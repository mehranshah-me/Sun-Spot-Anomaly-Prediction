{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "06b53b8e",
      "metadata": {
        "id": "06b53b8e"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b73ba151",
      "metadata": {
        "id": "b73ba151"
      },
      "outputs": [],
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None):\n",
        "    plt.plot(time[start:end], series[start:end], format)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.grid(True)\n",
        "TEMPERATURES_CSV = '/content/sunspotnorm.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ff9e4b40",
      "metadata": {
        "id": "ff9e4b40"
      },
      "outputs": [],
      "source": [
        "def parse_data_from_file(filename):\n",
        "\n",
        "    times = []\n",
        "    temperatures = []\n",
        "\n",
        "    with open(filename) as csvfile:\n",
        "\n",
        "        ### START CODE HERE\n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        next(reader)\n",
        "        for row in reader:\n",
        "            temperatures.append(float(row[1]))\n",
        "            times.append(row[0])\n",
        "        ### END CODE HERE\n",
        "\n",
        "    return times, temperatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dd601e6d",
      "metadata": {
        "id": "dd601e6d"
      },
      "outputs": [],
      "source": [
        "# visual relationship\n",
        "\n",
        "def visual_relationship(T, i, j):\n",
        "    \"\"\"\n",
        "    Calculates the visual relationship between nodes i and j in a time series T.\n",
        "\n",
        "    Args:\n",
        "        T (array-like): The time series.\n",
        "        i (int): The index of the first node.\n",
        "        j (int): The index of the second node.\n",
        "\n",
        "    Returns:\n",
        "        int: If nodes i and j are visible, returns 1. Otherwise, returns 0.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the slope between nodes i and j\n",
        "    slope_i_j = (T[j][1] - T[i][1]) / (j - i)\n",
        "\n",
        "    # Calculate the slopes between node i and each node between i and j\n",
        "    slopes_i_theta = ((T[i+1:j+1,1] - T[i][1]) / (np.arange(j-i)+1)).reshape(-1,1)\n",
        "\n",
        "    # Find the index of the maximum slope between node i and each node between i and j\n",
        "    max_slope_idx = np.max(slopes_i_theta)\n",
        "\n",
        "    # If the index of the maximum slope is equal to i, return 1. Otherwise, return 0.\n",
        "    if max_slope_idx == slope_i_j:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# visual matrix\n",
        "\n",
        "def visual_matrix(T):\n",
        "    \"\"\"\n",
        "    Calculates the visual matrix A for the time series T.\n",
        "\n",
        "    Args:\n",
        "        T (array-like): The time series.\n",
        "\n",
        "    Returns:\n",
        "        ndarray: The visual matrix A.\n",
        "    \"\"\"\n",
        "\n",
        "    n = T.shape[0]\n",
        "    A = np.zeros((n, n), dtype=int)\n",
        "\n",
        "    for i in range(n):\n",
        "        print(f\"{i} iteration : Visual Matrix\")\n",
        "        for j in range(i+1, n):\n",
        "            A[i][j] = visual_relationship(T, i, j)\n",
        "            A[j][i] = A[i][j]\n",
        "\n",
        "\n",
        "    return A\n",
        "\n",
        "# Enhanced visibility graph\n",
        "\n",
        "def enhanced_visibility_graph(T, A):\n",
        "    \"\"\"\n",
        "    Calculates the enhanced visibility graph (EVG) for the time series T and its visual matrix A.\n",
        "\n",
        "    Args:\n",
        "        T (ndarray): The time series, where each row is of the form (time, value).\n",
        "        A (ndarray): The visual matrix A for the time series.\n",
        "\n",
        "    Returns:\n",
        "        ndarray: The enhanced adjacency matrix B.\n",
        "    \"\"\"\n",
        "\n",
        "    n = T.shape[0]\n",
        "    B = np.zeros((n, n))\n",
        "\n",
        "    for i in range(n):\n",
        "        print(f\"{i} iteration : evg\")\n",
        "        degree = np.sum(A[i])\n",
        "        for j in range(n):\n",
        "            if A[i][j] == 1:\n",
        "                B[i][j] = (A[i][j] * T[j][1]) / degree\n",
        "\n",
        "    return B\n",
        "\n",
        "# Compressed Series\n",
        "\n",
        "def compress_evg(B):\n",
        "    \"\"\"\n",
        "    Compresses the enhanced adjacency matrix B generated by the EVG algorithm to generate a Deep Visibility Series (DVS) module.\n",
        "\n",
        "    Args:\n",
        "        B (ndarray): The enhanced adjacency matrix B.\n",
        "\n",
        "    Returns:\n",
        "        ndarray: The compressed DVS sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    n = B.shape[0]\n",
        "    zip_ = np.zeros(n)\n",
        "\n",
        "    for i in range(n):\n",
        "        print(f\"{i} iteration : zip\")\n",
        "        zip_[i] = np.sum(B[:,i])\n",
        "\n",
        "    return zip_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0a916b79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a916b79",
        "outputId": "ca4dfab6-0039-4738-f21e-d4349c68af10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [2. 0.]\n",
            " [3. 0.]\n",
            " [4. 0.]\n",
            " [5. 0.]]\n"
          ]
        }
      ],
      "source": [
        "times, temperatures = parse_data_from_file('/content/sunspotnorm.csv')\n",
        "time_series = np.array((range(len(times)),temperatures))\n",
        "series = np.array([(i+1,num) for i,num in enumerate(temperatures)])\n",
        "print(series[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c747503c",
      "metadata": {
        "scrolled": true,
        "id": "c747503c"
      },
      "outputs": [],
      "source": [
        "# Test your function and save all \"global\" variables within the G class (G stands for global)\n",
        "@dataclass\n",
        "class G:\n",
        "\n",
        "    times, temperatures = parse_data_from_file(TEMPERATURES_CSV)\n",
        "    time_series = np.array([(i+1,num) for i,num in enumerate(temperatures)])\n",
        "    TIME = np.array(times)\n",
        "    SERIES = np.array(temperatures)\n",
        "    #ZIP = compress_evg(enhanced_visibility_graph(time_series,visual_matrix(time_series)))\n",
        "    SPLIT_TIME = 2500\n",
        "    WINDOW_SIZE = 64\n",
        "    BATCH_SIZE = 32\n",
        "    SHUFFLE_BUFFER_SIZE = 1000\n",
        "\n",
        "#plt.figure(figsize=(10, 6))\n",
        "#plot_series(G.TIME, G.SERIES)\n",
        "#plot_series(G.TIME, G.ZIP)\n",
        "#plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZfSI6abtv-i"
      },
      "id": "UZfSI6abtv-i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "638abd6d",
      "metadata": {
        "id": "638abd6d"
      },
      "outputs": [],
      "source": [
        "def train_val_split(time, series, time_step=G.SPLIT_TIME):\n",
        "\n",
        "    time_train = time[:time_step]\n",
        "    series_train = series[:time_step]\n",
        "    time_valid = time[time_step:]\n",
        "    series_valid = series[time_step:]\n",
        "\n",
        "    return time_train, series_train, time_valid, series_valid\n",
        "\n",
        "\n",
        "# Split the dataset\n",
        "time_train, series_train, time_valid, series_valid = train_val_split(G.TIME, G.SERIES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2f8312c1",
      "metadata": {
        "id": "2f8312c1"
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[-1]))\n",
        "    ds = ds.batch(batch_size).prefetch(1)\n",
        "    return ds\n",
        "\n",
        "\n",
        "# Apply the transformation to the training set\n",
        "train_set = windowed_dataset(series_train, window_size=G.WINDOW_SIZE, batch_size=G.BATCH_SIZE, shuffle_buffer=G.SHUFFLE_BUFFER_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c31913e6",
      "metadata": {
        "id": "c31913e6"
      },
      "outputs": [],
      "source": [
        "def create_uncompiled_model():\n",
        "\n",
        "\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n",
        " strides=1, padding=\"causal\",\n",
        " activation=\"relu\",\n",
        " input_shape=[None, 1]),\n",
        " tf.keras.layers.LSTM(60, return_sequences=True),\n",
        " tf.keras.layers.LSTM(60),\n",
        " tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        " tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        " tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c7a32b6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7a32b6d",
        "outputId": "564c7f47-1951-4df6-dc2c-4adb66049161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing model prediction with input of shape (32, 64)...\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Your current architecture is compatible with the windowed dataset! :)\n"
          ]
        }
      ],
      "source": [
        "# Test your uncompiled model\n",
        "\n",
        "# Create an instance of the model\n",
        "uncompiled_model = create_uncompiled_model()\n",
        "\n",
        "# Get one batch of the training set(X = input, y = label)\n",
        "for X, y in train_set.take(1):\n",
        "\n",
        "    # Generate a prediction\n",
        "    print(f'Testing model prediction with input of shape {X.shape}...')\n",
        "    y_pred = uncompiled_model.predict(X)\n",
        "\n",
        "# Compare the shape of the prediction and the label y (remove dimensions of size 1)\n",
        "y_pred_shape = y_pred.squeeze().shape\n",
        "\n",
        "assert y_pred_shape == y.shape, (f'Squeezed predicted y shape = {y_pred_shape} '\n",
        "                                           f'whereas actual y shape = {y.shape}.')\n",
        "\n",
        "print(\"Your current architecture is compatible with the windowed dataset! :)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "b69c0847",
      "metadata": {
        "id": "b69c0847"
      },
      "outputs": [],
      "source": [
        "def adjust_learning_rate(dataset):\n",
        "\n",
        "    model = create_uncompiled_model()\n",
        "\n",
        "    lr_schedule = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 20))\n",
        "\n",
        "    # Select your optimizer\n",
        "    optimizer =  tf.keras.optimizers.SGD(learning_rate=0.0028, momentum=0.9)\n",
        "\n",
        "    # Compile the model passing in the appropriate loss\n",
        "    model.compile(loss=tf.keras.losses.Huber(),\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=[\"mae\"])\n",
        "\n",
        "    history = model.fit(dataset, epochs=100, callbacks=[lr_schedule])\n",
        "\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "199c3142",
      "metadata": {
        "id": "199c3142"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "fd42dee0",
      "metadata": {
        "id": "fd42dee0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "3b896d60",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b896d60",
        "outputId": "2405192f-2e6d-4caa-a8d7-ad1758db2937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "77/77 [==============================] - 10s 71ms/step - loss: 0.0015 - mae: 0.0269 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "77/77 [==============================] - 5s 67ms/step - loss: 0.0014 - mae: 0.0286 - lr: 1.1220e-04\n",
            "Epoch 3/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0013 - mae: 0.0304 - lr: 1.2589e-04\n",
            "Epoch 4/100\n",
            "77/77 [==============================] - 6s 71ms/step - loss: 0.0012 - mae: 0.0319 - lr: 1.4125e-04\n",
            "Epoch 5/100\n",
            "77/77 [==============================] - 5s 69ms/step - loss: 0.0012 - mae: 0.0332 - lr: 1.5849e-04\n",
            "Epoch 6/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0012 - mae: 0.0340 - lr: 1.7783e-04\n",
            "Epoch 7/100\n",
            "77/77 [==============================] - 6s 73ms/step - loss: 0.0011 - mae: 0.0347 - lr: 1.9953e-04\n",
            "Epoch 8/100\n",
            "77/77 [==============================] - 7s 94ms/step - loss: 0.0011 - mae: 0.0350 - lr: 2.2387e-04\n",
            "Epoch 9/100\n",
            "77/77 [==============================] - 6s 80ms/step - loss: 0.0011 - mae: 0.0357 - lr: 2.5119e-04\n",
            "Epoch 10/100\n",
            "77/77 [==============================] - 6s 68ms/step - loss: 0.0011 - mae: 0.0359 - lr: 2.8184e-04\n",
            "Epoch 11/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0011 - mae: 0.0358 - lr: 3.1623e-04\n",
            "Epoch 12/100\n",
            "77/77 [==============================] - 6s 79ms/step - loss: 0.0011 - mae: 0.0358 - lr: 3.5481e-04\n",
            "Epoch 13/100\n",
            "77/77 [==============================] - 6s 71ms/step - loss: 0.0011 - mae: 0.0359 - lr: 3.9811e-04\n",
            "Epoch 14/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0011 - mae: 0.0359 - lr: 4.4668e-04\n",
            "Epoch 15/100\n",
            "77/77 [==============================] - 6s 81ms/step - loss: 0.0011 - mae: 0.0360 - lr: 5.0119e-04\n",
            "Epoch 16/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0358 - lr: 5.6234e-04\n",
            "Epoch 17/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0011 - mae: 0.0357 - lr: 6.3096e-04\n",
            "Epoch 18/100\n",
            "77/77 [==============================] - 5s 67ms/step - loss: 0.0011 - mae: 0.0360 - lr: 7.0795e-04\n",
            "Epoch 19/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0361 - lr: 7.9433e-04\n",
            "Epoch 20/100\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.0011 - mae: 0.0359 - lr: 8.9125e-04\n",
            "Epoch 21/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0011 - mae: 0.0360 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "77/77 [==============================] - 6s 76ms/step - loss: 0.0011 - mae: 0.0357 - lr: 0.0011\n",
            "Epoch 23/100\n",
            "77/77 [==============================] - 6s 73ms/step - loss: 0.0011 - mae: 0.0350 - lr: 0.0013\n",
            "Epoch 24/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0350 - lr: 0.0014\n",
            "Epoch 25/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0349 - lr: 0.0016\n",
            "Epoch 26/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0352 - lr: 0.0018\n",
            "Epoch 27/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0011 - mae: 0.0346 - lr: 0.0020\n",
            "Epoch 28/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0346 - lr: 0.0022\n",
            "Epoch 29/100\n",
            "77/77 [==============================] - 6s 79ms/step - loss: 0.0011 - mae: 0.0344 - lr: 0.0025\n",
            "Epoch 30/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0344 - lr: 0.0028\n",
            "Epoch 31/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0344 - lr: 0.0032\n",
            "Epoch 32/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0011 - mae: 0.0343 - lr: 0.0035\n",
            "Epoch 33/100\n",
            "77/77 [==============================] - 6s 68ms/step - loss: 0.0011 - mae: 0.0338 - lr: 0.0040\n",
            "Epoch 34/100\n",
            "77/77 [==============================] - 6s 74ms/step - loss: 0.0011 - mae: 0.0345 - lr: 0.0045\n",
            "Epoch 35/100\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 0.0011 - mae: 0.0337 - lr: 0.0050\n",
            "Epoch 36/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0340 - lr: 0.0056\n",
            "Epoch 37/100\n",
            "77/77 [==============================] - 7s 84ms/step - loss: 0.0011 - mae: 0.0338 - lr: 0.0063\n",
            "Epoch 38/100\n",
            "77/77 [==============================] - 6s 78ms/step - loss: 0.0011 - mae: 0.0340 - lr: 0.0071\n",
            "Epoch 39/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0337 - lr: 0.0079\n",
            "Epoch 40/100\n",
            "77/77 [==============================] - 8s 105ms/step - loss: 0.0010 - mae: 0.0333 - lr: 0.0089\n",
            "Epoch 41/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0335 - lr: 0.0100\n",
            "Epoch 42/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0337 - lr: 0.0112\n",
            "Epoch 43/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0010 - mae: 0.0335 - lr: 0.0126\n",
            "Epoch 44/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0337 - lr: 0.0141\n",
            "Epoch 45/100\n",
            "77/77 [==============================] - 7s 82ms/step - loss: 0.0011 - mae: 0.0334 - lr: 0.0158\n",
            "Epoch 46/100\n",
            "77/77 [==============================] - 6s 68ms/step - loss: 0.0010 - mae: 0.0333 - lr: 0.0178\n",
            "Epoch 47/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0010 - mae: 0.0329 - lr: 0.0200\n",
            "Epoch 48/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0010 - mae: 0.0327 - lr: 0.0224\n",
            "Epoch 49/100\n",
            "77/77 [==============================] - 6s 78ms/step - loss: 0.0010 - mae: 0.0322 - lr: 0.0251\n",
            "Epoch 50/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0010 - mae: 0.0325 - lr: 0.0282\n",
            "Epoch 51/100\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 0.0010 - mae: 0.0325 - lr: 0.0316\n",
            "Epoch 52/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0010 - mae: 0.0323 - lr: 0.0355\n",
            "Epoch 53/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0010 - mae: 0.0328 - lr: 0.0398\n",
            "Epoch 54/100\n",
            "77/77 [==============================] - 6s 77ms/step - loss: 0.0010 - mae: 0.0319 - lr: 0.0447\n",
            "Epoch 55/100\n",
            "77/77 [==============================] - 6s 75ms/step - loss: 0.0010 - mae: 0.0317 - lr: 0.0501\n",
            "Epoch 56/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0012 - mae: 0.0354 - lr: 0.0562\n",
            "Epoch 57/100\n",
            "77/77 [==============================] - 6s 74ms/step - loss: 0.0010 - mae: 0.0326 - lr: 0.0631\n",
            "Epoch 58/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0010 - mae: 0.0321 - lr: 0.0708\n",
            "Epoch 59/100\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 0.0011 - mae: 0.0322 - lr: 0.0794\n",
            "Epoch 60/100\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 0.0010 - mae: 0.0322 - lr: 0.0891\n",
            "Epoch 61/100\n",
            "77/77 [==============================] - 6s 79ms/step - loss: 0.0011 - mae: 0.0332 - lr: 0.1000\n",
            "Epoch 62/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0010 - mae: 0.0315 - lr: 0.1122\n",
            "Epoch 63/100\n",
            "77/77 [==============================] - 5s 69ms/step - loss: 0.0010 - mae: 0.0318 - lr: 0.1259\n",
            "Epoch 64/100\n",
            "77/77 [==============================] - 5s 69ms/step - loss: 0.0010 - mae: 0.0317 - lr: 0.1413\n",
            "Epoch 65/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0010 - mae: 0.0312 - lr: 0.1585\n",
            "Epoch 66/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0334 - lr: 0.1778\n",
            "Epoch 67/100\n",
            "77/77 [==============================] - 7s 87ms/step - loss: 0.0010 - mae: 0.0317 - lr: 0.1995\n",
            "Epoch 68/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0335 - lr: 0.2239\n",
            "Epoch 69/100\n",
            "77/77 [==============================] - 6s 75ms/step - loss: 0.0011 - mae: 0.0325 - lr: 0.2512\n",
            "Epoch 70/100\n",
            "77/77 [==============================] - 7s 87ms/step - loss: 9.9790e-04 - mae: 0.0312 - lr: 0.2818\n",
            "Epoch 71/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0335 - lr: 0.3162\n",
            "Epoch 72/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0010 - mae: 0.0314 - lr: 0.3548\n",
            "Epoch 73/100\n",
            "77/77 [==============================] - 7s 84ms/step - loss: 0.0011 - mae: 0.0343 - lr: 0.3981\n",
            "Epoch 74/100\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 9.8795e-04 - mae: 0.0306 - lr: 0.4467\n",
            "Epoch 75/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0338 - lr: 0.5012\n",
            "Epoch 76/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0012 - mae: 0.0361 - lr: 0.5623\n",
            "Epoch 77/100\n",
            "77/77 [==============================] - 7s 80ms/step - loss: 9.9359e-04 - mae: 0.0313 - lr: 0.6310\n",
            "Epoch 78/100\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 0.0011 - mae: 0.0344 - lr: 0.7079\n",
            "Epoch 79/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0011 - mae: 0.0345 - lr: 0.7943\n",
            "Epoch 80/100\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 0.0012 - mae: 0.0375 - lr: 0.8913\n",
            "Epoch 81/100\n",
            "77/77 [==============================] - 7s 84ms/step - loss: 0.0011 - mae: 0.0335 - lr: 1.0000\n",
            "Epoch 82/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0013 - mae: 0.0365 - lr: 1.1220\n",
            "Epoch 83/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0014 - mae: 0.0386 - lr: 1.2589\n",
            "Epoch 84/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0014 - mae: 0.0400 - lr: 1.4125\n",
            "Epoch 85/100\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0013 - mae: 0.0380 - lr: 1.5849\n",
            "Epoch 86/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0012 - mae: 0.0366 - lr: 1.7783\n",
            "Epoch 87/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0020 - mae: 0.0495 - lr: 1.9953\n",
            "Epoch 88/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0017 - mae: 0.0448 - lr: 2.2387\n",
            "Epoch 89/100\n",
            "77/77 [==============================] - 6s 74ms/step - loss: 0.0050 - mae: 0.0822 - lr: 2.5119\n",
            "Epoch 90/100\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0031 - mae: 0.0611 - lr: 2.8184\n",
            "Epoch 91/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0032 - mae: 0.0613 - lr: 3.1623\n",
            "Epoch 92/100\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0230 - mae: 0.1812 - lr: 3.5481\n",
            "Epoch 93/100\n",
            "77/77 [==============================] - 6s 75ms/step - loss: 1.2134 - mae: 1.6692 - lr: 3.9811\n",
            "Epoch 94/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 3.2296 - mae: 3.7013 - lr: 4.4668\n",
            "Epoch 95/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 2.8420 - mae: 3.3364 - lr: 5.0119\n",
            "Epoch 96/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 3.8061 - mae: 4.2890 - lr: 5.6234\n",
            "Epoch 97/100\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 4.1369 - mae: 4.6276 - lr: 6.3096\n",
            "Epoch 98/100\n",
            "77/77 [==============================] - 6s 79ms/step - loss: 3.2105 - mae: 3.7105 - lr: 7.0795\n",
            "Epoch 99/100\n",
            "77/77 [==============================] - 6s 73ms/step - loss: 5.2433 - mae: 5.7217 - lr: 7.9433\n",
            "Epoch 100/100\n",
            "77/77 [==============================] - 6s 71ms/step - loss: 7.7782 - mae: 8.2648 - lr: 8.9125\n"
          ]
        }
      ],
      "source": [
        "# Run the training with dynamic LR\n",
        "lr_history = adjust_learning_rate(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "56f2a79a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "56f2a79a",
        "outputId": "4d775c8f-97c5-46a4-c7ca-558ff254c6c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0001, 10.0, 0.0, 10.0)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.semilogx(lr_history.history[\"lr\"], lr_history.history[\"loss\"])\n",
        "plt.axis([1e-4, 10, 0, 10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ff08233b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff08233b",
        "outputId": "34806086-7f5a-422b-c7f5-d6e3183aef59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4466836"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "l=lr_history.history[\"lr\"][lr_history.history[\"loss\"].index(min(lr_history.history[\"loss\"]))]\n",
        "l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "144384bd",
      "metadata": {
        "id": "144384bd"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "\n",
        "\n",
        "    model = create_uncompiled_model()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate = l,momentum = 0.9)\n",
        "    model.compile(loss=tf.keras.losses.Huber(),\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=[\"mae\"])\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "c97c2248",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c97c2248",
        "outputId": "dad74a18-eebc-4d81-a334-1197ea2c23f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "77/77 [==============================] - 10s 69ms/step - loss: 0.0014 - mae: 0.0388\n",
            "Epoch 2/50\n",
            "77/77 [==============================] - 7s 83ms/step - loss: 0.0013 - mae: 0.0367\n",
            "Epoch 3/50\n",
            "77/77 [==============================] - 7s 83ms/step - loss: 0.0013 - mae: 0.0374\n",
            "Epoch 4/50\n",
            "77/77 [==============================] - 5s 67ms/step - loss: 0.0012 - mae: 0.0353\n",
            "Epoch 5/50\n",
            "77/77 [==============================] - 7s 82ms/step - loss: 0.0012 - mae: 0.0358\n",
            "Epoch 6/50\n",
            "77/77 [==============================] - 7s 84ms/step - loss: 0.0012 - mae: 0.0355\n",
            "Epoch 7/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0338\n",
            "Epoch 8/50\n",
            "77/77 [==============================] - 6s 78ms/step - loss: 0.0012 - mae: 0.0350\n",
            "Epoch 9/50\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0011 - mae: 0.0343\n",
            "Epoch 10/50\n",
            "77/77 [==============================] - 6s 74ms/step - loss: 0.0011 - mae: 0.0329\n",
            "Epoch 11/50\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 0.0012 - mae: 0.0354\n",
            "Epoch 12/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0331\n",
            "Epoch 13/50\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0010 - mae: 0.0317\n",
            "Epoch 14/50\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0325\n",
            "Epoch 15/50\n",
            "77/77 [==============================] - 7s 83ms/step - loss: 0.0012 - mae: 0.0345\n",
            "Epoch 16/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0011 - mae: 0.0325\n",
            "Epoch 17/50\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0010 - mae: 0.0327\n",
            "Epoch 18/50\n",
            "77/77 [==============================] - 7s 84ms/step - loss: 0.0011 - mae: 0.0335\n",
            "Epoch 19/50\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 0.0011 - mae: 0.0333\n",
            "Epoch 20/50\n",
            "77/77 [==============================] - 7s 83ms/step - loss: 9.6154e-04 - mae: 0.0302\n",
            "Epoch 21/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 9.9659e-04 - mae: 0.0312\n",
            "Epoch 22/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 9.8394e-04 - mae: 0.0315\n",
            "Epoch 23/50\n",
            "77/77 [==============================] - 5s 69ms/step - loss: 0.0010 - mae: 0.0314\n",
            "Epoch 24/50\n",
            "77/77 [==============================] - 7s 83ms/step - loss: 9.4470e-04 - mae: 0.0298\n",
            "Epoch 25/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0010 - mae: 0.0332\n",
            "Epoch 26/50\n",
            "77/77 [==============================] - 6s 75ms/step - loss: 9.9012e-04 - mae: 0.0308\n",
            "Epoch 27/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0010 - mae: 0.0332\n",
            "Epoch 28/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 9.7027e-04 - mae: 0.0310\n",
            "Epoch 29/50\n",
            "77/77 [==============================] - 5s 69ms/step - loss: 0.0010 - mae: 0.0321\n",
            "Epoch 30/50\n",
            "77/77 [==============================] - 6s 79ms/step - loss: 0.0010 - mae: 0.0316\n",
            "Epoch 31/50\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 9.1529e-04 - mae: 0.0293\n",
            "Epoch 32/50\n",
            "77/77 [==============================] - 6s 75ms/step - loss: 0.0010 - mae: 0.0321\n",
            "Epoch 33/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 0.0010 - mae: 0.0316\n",
            "Epoch 34/50\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 9.4169e-04 - mae: 0.0300\n",
            "Epoch 35/50\n",
            "77/77 [==============================] - 7s 85ms/step - loss: 0.0011 - mae: 0.0327\n",
            "Epoch 36/50\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 9.0783e-04 - mae: 0.0296\n",
            "Epoch 37/50\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 0.0010 - mae: 0.0323\n",
            "Epoch 38/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 9.7848e-04 - mae: 0.0318\n",
            "Epoch 39/50\n",
            "77/77 [==============================] - 5s 68ms/step - loss: 9.4575e-04 - mae: 0.0309\n",
            "Epoch 40/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 8.7191e-04 - mae: 0.0280\n",
            "Epoch 41/50\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 9.3135e-04 - mae: 0.0303\n",
            "Epoch 42/50\n",
            "77/77 [==============================] - 6s 78ms/step - loss: 9.7604e-04 - mae: 0.0323\n",
            "Epoch 43/50\n",
            "77/77 [==============================] - 6s 73ms/step - loss: 8.7655e-04 - mae: 0.0287\n",
            "Epoch 44/50\n",
            "77/77 [==============================] - 6s 72ms/step - loss: 9.3558e-04 - mae: 0.0301\n",
            "Epoch 45/50\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 9.5553e-04 - mae: 0.0308\n",
            "Epoch 46/50\n",
            "77/77 [==============================] - 6s 69ms/step - loss: 8.9968e-04 - mae: 0.0294\n",
            "Epoch 47/50\n",
            "77/77 [==============================] - 6s 70ms/step - loss: 9.1789e-04 - mae: 0.0297\n",
            "Epoch 48/50\n",
            "77/77 [==============================] - 6s 77ms/step - loss: 8.5871e-04 - mae: 0.0289\n",
            "Epoch 49/50\n",
            "77/77 [==============================] - 7s 86ms/step - loss: 8.4236e-04 - mae: 0.0280\n",
            "Epoch 50/50\n",
            "77/77 [==============================] - 6s 79ms/step - loss: 8.5066e-04 - mae: 0.0287\n"
          ]
        }
      ],
      "source": [
        "# Save an instance of the model\n",
        "model = create_model()\n",
        "\n",
        "# Train it\n",
        "history = model.fit(train_set, epochs=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "8d509e0c",
      "metadata": {
        "id": "8d509e0c"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(true_series, forecast):\n",
        "\n",
        "    mse = tf.keras.metrics.mean_squared_error(true_series, forecast).numpy()\n",
        "    mae = tf.keras.metrics.mean_absolute_error(true_series, forecast).numpy()\n",
        "\n",
        "    return mse, mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b99d064b",
      "metadata": {
        "id": "b99d064b"
      },
      "outputs": [],
      "source": [
        "def model_forecast(model, series, window_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.batch(32).prefetch(1)\n",
        "    forecast = model.predict(ds)\n",
        "    return forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "22c2c3e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22c2c3e5",
        "outputId": "6ac2752e-4697-4f20-9e69-2af2536f7dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2302/2302 [==============================] - 65s 28ms/step\n"
          ]
        }
      ],
      "source": [
        "# Compute the forecast for all the series\n",
        "rnn_forecast = model_forecast(model, G.SERIES, G.WINDOW_SIZE).squeeze()\n",
        "\n",
        "# Slice the forecast to get only the predictions for the validation set\n",
        "rnn_forecast = rnn_forecast[G.SPLIT_TIME - G.WINDOW_SIZE:-1]\n",
        "\n",
        "# Plot the forecast\n",
        "#plt.figure(figsize=(10, 6))\n",
        "#plot_series(time_valid, series_valid)\n",
        "#plot_series(time_valid, rnn_forecast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "146a93ca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "146a93ca",
        "outputId": "5fbaa6ab-81dd-4d1f-f542-0d46b01a5627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mse: 0.01, mae: 0.07 for forecast\n"
          ]
        }
      ],
      "source": [
        "mse, mae = compute_metrics(series_valid, rnn_forecast)\n",
        "\n",
        "print(f\"mse: {mse:.2f}, mae: {mae:.2f} for forecast\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab0a35d",
      "metadata": {
        "id": "3ab0a35d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f9d1b19",
      "metadata": {
        "id": "2f9d1b19"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb8bbbe",
      "metadata": {
        "id": "dbb8bbbe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83c9e42c",
      "metadata": {
        "id": "83c9e42c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de72572",
      "metadata": {
        "id": "0de72572"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a66d552",
      "metadata": {
        "id": "6a66d552"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5826492",
      "metadata": {
        "id": "d5826492"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}